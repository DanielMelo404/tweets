{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5329</th>\n",
       "      <td>7608</td>\n",
       "      <td>pandemonium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Proud of you @JoeGoodmanJr for watching the #C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>7609</td>\n",
       "      <td>pandemonium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pandemonium In Aba As Woman Delivers Baby With...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5331</th>\n",
       "      <td>7610</td>\n",
       "      <td>pandemonium</td>\n",
       "      <td>??????</td>\n",
       "      <td>#Pandemonium.iso psp http://t.co/HbpNFOAwII</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332</th>\n",
       "      <td>7611</td>\n",
       "      <td>pandemonium</td>\n",
       "      <td>The P (South Philly)</td>\n",
       "      <td>Pandemonium use to be my fav cd ?? I had to ge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>7612</td>\n",
       "      <td>pandemonium</td>\n",
       "      <td>VONT ISLAND, LAGOS</td>\n",
       "      <td>Pandemonium In Aba As Woman Delivers Baby With...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7607</th>\n",
       "      <td>10867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#stormchase Violent Record Breaking EF-5 El Re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      keyword              location  \\\n",
       "5329   7608  pandemonium                   NaN   \n",
       "5330   7609  pandemonium                   NaN   \n",
       "5331   7610  pandemonium                ??????   \n",
       "5332   7611  pandemonium  The P (South Philly)   \n",
       "5333   7612  pandemonium    VONT ISLAND, LAGOS   \n",
       "...     ...          ...                   ...   \n",
       "7607  10867          NaN                   NaN   \n",
       "7608  10869          NaN                   NaN   \n",
       "7609  10870          NaN                   NaN   \n",
       "7610  10871          NaN                   NaN   \n",
       "7611  10872          NaN                   NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "5329  Proud of you @JoeGoodmanJr for watching the #C...       0  \n",
       "5330  Pandemonium In Aba As Woman Delivers Baby With...       0  \n",
       "5331        #Pandemonium.iso psp http://t.co/HbpNFOAwII       0  \n",
       "5332  Pandemonium use to be my fav cd ?? I had to ge...       1  \n",
       "5333  Pandemonium In Aba As Woman Delivers Baby With...       0  \n",
       "...                                                 ...     ...  \n",
       "7607  #stormchase Violent Record Breaking EF-5 El Re...       1  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "\n",
       "[2283 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "one_hot_encoded_df= pd.read_csv(\"\")\n",
    "n_letters = one_hot_encoded_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        !   !!  !!!  !!!!  !!!!!  !!!!!!!!!!!#MetroFmTalk  !The    #  ##book  \\\n",
      "0     0.0  0.0  0.0   0.0    0.0                      0.0   0.0  0.0     0.0   \n",
      "1     0.0  0.0  0.0   0.0    0.0                      0.0   0.0  0.0     0.0   \n",
      "2     0.0  0.0  0.0   0.0    0.0                      0.0   0.0  0.0     0.0   \n",
      "3     0.0  0.0  0.0   0.0    0.0                      0.0   0.0  0.0     0.0   \n",
      "4     0.0  0.0  0.0   0.0    0.0                      0.0   0.0  0.0     0.0   \n",
      "...   ...  ...  ...   ...    ...                      ...   ...  ...     ...   \n",
      "7608  0.0  0.0  0.0   0.0    0.0                      0.0   0.0  0.0     0.0   \n",
      "7609  0.0  0.0  0.0   0.0    0.0                      0.0   0.0  0.0     0.0   \n",
      "7610  0.0  0.0  0.0   0.0    0.0                      0.0   0.0  0.0     0.0   \n",
      "7611  0.0  0.0  0.0   0.0    0.0                      0.0   0.0  0.0     0.0   \n",
      "7612  0.0  0.0  0.0   0.0    0.0                      0.0   0.0  0.0     0.0   \n",
      "\n",
      "      ##fukushima  ...  å£9!  å¤}   å¨  å©Daniel  å¬'Only   åÇ   åÈ  \\\n",
      "0             0.0  ...   0.0  0.0  0.0       0.0      0.0  0.0  0.0   \n",
      "1             0.0  ...   0.0  0.0  0.0       0.0      0.0  0.0  0.0   \n",
      "2             0.0  ...   0.0  0.0  0.0       0.0      0.0  0.0  0.0   \n",
      "3             0.0  ...   0.0  0.0  0.0       0.0      0.0  0.0  0.0   \n",
      "4             0.0  ...   0.0  0.0  0.0       0.0      0.0  0.0  0.0   \n",
      "...           ...  ...   ...  ...  ...       ...      ...  ...  ...   \n",
      "7608          0.0  ...   0.0  0.0  0.0       0.0      0.0  0.0  0.0   \n",
      "7609          0.0  ...   0.0  0.0  0.0       0.0      0.0  0.0  0.0   \n",
      "7610          0.0  ...   0.0  0.0  0.0       0.0      0.0  0.0  0.0   \n",
      "7611          0.0  ...   0.0  0.0  0.0       0.0      0.0  0.0  0.0   \n",
      "7612          0.0  ...   0.0  0.0  0.0       0.0      0.0  0.0  0.0   \n",
      "\n",
      "      åÈMGN-AFRICAå¨   åÊ  åÊFedEx  \n",
      "0                0.0  0.0      0.0  \n",
      "1                0.0  0.0      0.0  \n",
      "2                0.0  0.0      0.0  \n",
      "3                0.0  0.0      0.0  \n",
      "4                0.0  0.0      0.0  \n",
      "...              ...  ...      ...  \n",
      "7608             0.0  0.0      0.0  \n",
      "7609             0.0  0.0      0.0  \n",
      "7610             0.0  0.0      0.0  \n",
      "7611             0.0  0.0      0.0  \n",
      "7612             0.0  0.0      0.0  \n",
      "\n",
      "[7613 rows x 31924 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the tweets\n",
    "# Create the vocabulary\n",
    "vocabulary = np.array([])\n",
    "for i in range(len(df.index)):\n",
    "    words = df['text'].iloc[i].split()  \n",
    "    vocabulary = np.append(vocabulary, np.unique(words))  \n",
    "    vocabulary = np.unique(vocabulary)\n",
    "\n",
    "# Create a dictionary to map each word to an index\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "# Function to one-hot encode a tweet\n",
    "def one_hot_encode(tweet, vocab_size):\n",
    "    one_hot_vector = np.zeros(vocab_size)\n",
    "    for word in tweet.split():\n",
    "        if word in word_to_index:\n",
    "            index = word_to_index[word]\n",
    "            one_hot_vector[index] = 1\n",
    "    return one_hot_vector\n",
    "\n",
    "# Apply the one-hot encoding to each tweet\n",
    "one_hot_encoded_tweets = np.array([one_hot_encode(tweet, len(vocabulary)) for tweet in df['text']])\n",
    "\n",
    "# Convert to DataFrame for better readability (optional)\n",
    "one_hot_encoded_df = pd.DataFrame(one_hot_encoded_tweets, columns=vocabulary)\n",
    "# one_hot_encoded_df = one_hot_encoded_df.assign(category=df.target.to_list())\n",
    "print(one_hot_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31924"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.index\n",
    "n_letters = one_hot_encoded_df.shape[1]\n",
    "n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    \n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    \n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df_train = df.iloc[0:5329]\n",
    "df_test = df.iloc[5329:-1]\n",
    "df_test, df_train\n",
    "\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    line = line.split()\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# def randomTrainingExampleTest():\n",
    "#     category = randomChoice(all_categories)\n",
    "#     line = randomChoice(df_test[df_test.target==category].index)\n",
    "#     category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "#     line_tensor = lineToTensor(df_test.text.iloc[line])\n",
    "#     return category, line, category_tensor, line_tensor\n",
    "\n",
    "# randomTrainingExampleTest()\n",
    "\n",
    "lineToTensor(df_test.text.iloc[0])\n",
    "\n",
    "for i in range():\n",
    "    output, hidden = rnn(line_tensor[i], hidden)\n",
    "    \n",
    "    \n",
    "    # predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterToIndex(letter):\n",
    "    return one_hot_encoded_df.columns.get_loc(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or an array of one-hot letter vectors\n",
    "\n",
    "def lineToTensor(line):\n",
    "    line = line.split()\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = [1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m category, line, category_tensor, line_tensor\n\u001b[0;32m     13\u001b[0m randomChoice(all_categories)\n\u001b[1;32m---> 15\u001b[0m randomChoice(df[\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     17\u001b[0m randomTrainingExample()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\anaconda3\\envs\\alfa-unal\\lib\\site-packages\\pandas\\core\\generic.py:6293\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6287\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6288\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6289\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6290\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6291\u001b[0m ):\n\u001b[0;32m   6292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'target'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(df[df.target==category].index)\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(df.text.iloc[line])\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "randomChoice(all_categories)\n",
    "\n",
    "randomChoice(df[df.target==1].index)\n",
    "\n",
    "randomTrainingExample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection.train_test_split as train_test_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfa-unal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
